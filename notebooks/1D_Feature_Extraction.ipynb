{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2024391-13c6-44f4-a7e4-4303c94fbf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tüm segmentler için feature extraction tamamlandı!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "# --- Feature extraction fonksiyonu (19 feature) ---\n",
    "def extract_features(x):\n",
    "    N = len(x)\n",
    "    f = {}\n",
    "    f['peak'] = np.max(np.abs(x))\n",
    "    f['rms'] = np.sqrt(np.mean(x**2))\n",
    "    f['kurtosis'] = np.mean(((x-np.mean(x))/np.std(x))**4)\n",
    "    f['crest_factor'] = np.max(np.abs(x))/f['rms']\n",
    "    f['clearance_factor'] = (np.max(np.abs(x))/np.mean(np.sqrt(np.abs(x))))**2\n",
    "    f['impulse_factor'] = np.max(np.abs(x))/np.mean(np.abs(x))\n",
    "    f['shape_factor'] = f['rms']/np.mean(np.abs(x))\n",
    "    f['skewness'] = np.mean(((x-np.mean(x))/np.std(x))**3)\n",
    "    f['square_mean_root'] = (np.mean(np.sqrt(np.abs(x))))**2\n",
    "    f['moment_5'] = np.mean(((x-np.mean(x))/np.std(x))**5)\n",
    "    f['moment_6'] = np.mean(((x-np.mean(x))/np.std(x))**6)\n",
    "    f['mean'] = np.mean(x)\n",
    "    f['shape_factor2'] = f['square_mean_root']/np.mean(np.abs(x))\n",
    "    f['peak_to_peak'] = np.max(x) - np.min(x)\n",
    "    f['kurtosis_factor'] = f['kurtosis'] / ((np.mean(x**2))**2)\n",
    "    f['std'] = np.std(x)\n",
    "    f['smoothness'] = 1 - (1 + (np.std(x))**2)**0.5\n",
    "    f['uniformity'] = 1 - np.std(x)/np.mean(x) if np.mean(x)!=0 else 0\n",
    "    f['normal_neg_loglike'] = 1/(np.std(x)*np.sqrt(2*np.pi)) * np.exp(-(x-np.mean(x))**2/(2*np.std(x)**2)).mean()\n",
    "    return list(f.values())\n",
    "\n",
    "# --- Ayarlar ---\n",
    "fs = 10240\n",
    "start_idx = int(1.5 * fs)\n",
    "end_idx = int(4.5 * fs)\n",
    "segment_length = 1024\n",
    "root_dir = r\"C:\\Users\\VICTUS\\OneDrive\\Masaüstü\\EECSL\"   # Ana .mat dosyalarının olduğu klasör\n",
    "\n",
    "# Tüm segment log dosyalarının yolunu ver (split ve label ile)\n",
    "log_files = [\n",
    "    ('healthy', 'train', r\"C:\\Users\\VICTUS\\Pictures\\(1.5-4.5s)\\Reassigned(1.5-4.5s)\\healthy_train_segments.csv\"),\n",
    "    ('healthy', 'test', r\"C:\\Users\\VICTUS\\Pictures\\(1.5-4.5s)\\Reassigned(1.5-4.5s)\\healthy_test_segments.csv\"),\n",
    "    ('imbalance', 'train', r\"C:\\Users\\VICTUS\\Pictures\\(1.5-4.5s)\\Reassigned(1.5-4.5s)\\imbalance_train_segments.csv\"),\n",
    "    ('imbalance', 'test', r\"C:\\Users\\VICTUS\\Pictures\\(1.5-4.5s)\\Reassigned(1.5-4.5s)\\imbalance_test_segments.csv\"),\n",
    "    ('loose', 'train', r\"C:\\Users\\VICTUS\\Pictures\\(1.5-4.5s)\\Reassigned(1.5-4.5s)\\loose_train_segments.csv\"),\n",
    "    ('loose', 'test', r\"C:\\Users\\VICTUS\\Pictures\\(1.5-4.5s)\\Reassigned(1.5-4.5s)\\loose_test_segments.csv\"),\n",
    "    ('misalignment', 'train', r\"C:\\Users\\VICTUS\\Pictures\\(1.5-4.5s)\\Reassigned(1.5-4.5s)\\misalignment_train_segments.csv\"),\n",
    "    ('misalignment', 'test', r\"C:\\Users\\VICTUS\\Pictures\\(1.5-4.5s)\\Reassigned(1.5-4.5s)\\misalignment_test_segments.csv\"),\n",
    "]\n",
    "\n",
    "features_list = [] # Tüm segmentlerden çıkan feature vektörleri burada toplanacak.\n",
    "meta_list = [] # Her feature’ın split, label, matfile, channel, segment index bilgisi.\n",
    "mat_cache = {} # Aynı .mat dosyasını tekrar tekrar okumamak için “cache” (performans için).\n",
    "\n",
    "for label, split, log_path in log_files:\n",
    "    log_df = pd.read_csv(log_path) # Her bir label ve split kombinasyonu için ilgili segmentlerin bilgisini okur.\n",
    "    for idx, row in log_df.iterrows():\n",
    "        # Her segmentin, hangi .mat dosyasına, hangi channela (cur1, cur2), ve hangi segment başlangıç indexine ait olduğunu almak.\n",
    "        matfile = row['matfile']\n",
    "        channel = row['channel']\n",
    "        seg_idx = int(row['start_index'])\n",
    "\n",
    "        # .mat dosyasını bul (root_dir/label_start/...)\n",
    "        mat_path = os.path.join(root_dir, f\"{label}_start\", matfile + \".mat\")\n",
    "        if not os.path.exists(mat_path):\n",
    "            print(f\"Mat dosyası bulunamadı: {mat_path}\")\n",
    "            continue\n",
    "\n",
    "        # Aynı .mat dosyasını ve kanalı birden fazla okumamak için cache (önbellek) kullanılır.\n",
    "        cache_key = f\"{mat_path}_{channel}\"\n",
    "        if cache_key in mat_cache:\n",
    "            signal = mat_cache[cache_key]\n",
    "        else:\n",
    "            matdata = scipy.io.loadmat(mat_path)\n",
    "            if channel not in matdata:\n",
    "                print(f\"Kanallar arasında yok: {channel} in {mat_path}\")\n",
    "                continue\n",
    "            signal = matdata[channel].squeeze()\n",
    "            signal = signal[start_idx:end_idx]\n",
    "            mat_cache[cache_key] = signal\n",
    "\n",
    "        # Segmentin bitiş noktası, sinyal uzunluğunu aşıyorsa segmenti atlar.\n",
    "        if seg_idx+segment_length > len(signal):\n",
    "            print(f\"Segment sınırı aşıldı: {matfile}, {channel}, {seg_idx}\")\n",
    "            continue\n",
    "\n",
    "        segment = signal[seg_idx:seg_idx+segment_length] # Belirlenen başlangıç noktasından sonuna kadar veri çeker.\n",
    "        feat = extract_features(segment) # Bu segment için istatistiksel öznitelik çıkar.\n",
    "        # Sonuç vektörünü ve segmentin meta bilgisini listeye ekle.\n",
    "        features_list.append(feat)\n",
    "        meta_list.append([split, label, matfile, channel, seg_idx])\n",
    "\n",
    "# CSV dosyası oluşturma işlemi.\n",
    "\n",
    "# Python listesindeki tüm feature vektörlerini bir numpy array’e çevirir.\n",
    "features_arr = np.array(features_list) \n",
    "# # Her segmentin meta bilgisini (train/test, arıza tipi, dosya adı, kanal adı, segmentin başladığı index) içeren DataFrame oluşturmak.\n",
    "meta_df = pd.DataFrame(meta_list, columns=['split','label','matfile','channel','start_index']) \n",
    "# Her feature sütununa bir isim verip (feat_1, feat_2, ..., feat_19) DataFrame oluşturur.\n",
    "features_df = pd.DataFrame(features_arr, columns=[f'feat_{i+1}' for i in range(features_arr.shape[1])])\n",
    "# Meta bilgileri ve feature DataFrame’ini yan yana birleştirerek tek bir tablo (out_df) oluşturur.\n",
    "out_df = pd.concat([meta_df, features_df], axis=1)\n",
    "save_dir = r\"C:\\Users\\VICTUS\\OneDrive\\Masaüstü\\EECSL\"\n",
    "out_df.to_csv(os.path.join(save_dir, \"all_segments_1d_features.csv\"), index=False)\n",
    "print(\"Tüm segmentler için feature extraction tamamlandı!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f4bab5-458d-40b0-9bee-b657d8274603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train/healthy: 100%|██████████| 377/377 [00:02<00:00, 128.09it/s]\n",
      "train/imbalance: 100%|██████████| 377/377 [00:02<00:00, 147.26it/s]\n",
      "train/loose: 100%|██████████| 377/377 [00:01<00:00, 223.82it/s]\n",
      "train/misalignment: 100%|██████████| 377/377 [00:02<00:00, 181.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split için shape: X1=(1508, 19), X2=(1508, 224, 224, 3), y=(1508,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test/healthy: 100%|██████████| 95/95 [00:00<00:00, 139.11it/s]\n",
      "test/imbalance: 100%|██████████| 95/95 [00:00<00:00, 138.60it/s]\n",
      "test/loose: 100%|██████████| 95/95 [00:00<00:00, 133.17it/s]\n",
      "test/misalignment: 100%|██████████| 95/95 [00:00<00:00, 151.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test split için shape: X1=(380, 19), X2=(380, 224, 224, 3), y=(380,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1D feature csv'yi yükle\n",
    "df = pd.read_csv(\"all_segments_1d_features.csv\")\n",
    "\n",
    "# Tüm label'lar ve split'ler için (örnek: train/healthy)\n",
    "img_root = r\"C:\\Users\\VICTUS\\Pictures\\(1.5-4.5s)\\Reassigned(1.5-4.5s)\"\n",
    "splits = ['train', 'test']\n",
    "labels = ['healthy', 'imbalance', 'loose', 'misalignment']\n",
    "\n",
    "for split in splits:\n",
    "    X1 = [] # 1D featureler.\n",
    "    X2 = [] # 2D görseller\n",
    "    y = [] # Etiketler\n",
    "\n",
    "    for label in labels:\n",
    "        # O split ve label için .csv satırlarını seç\n",
    "        # Belirli bir split ve label için tüm segmentlerin DataFrame’i çekilir.\n",
    "        subset = df[(df['split']==split) & (df['label']==label)].reset_index(drop=True)\n",
    "\n",
    "        # Görsel klasörünü tara\n",
    "        img_dir = os.path.join(img_root, split, label)\n",
    "        img_files = sorted(os.listdir(img_dir), key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "        assert len(img_files) == len(subset), f\"{label}/{split} eşleşme sorunu: {len(img_files)} görsel, {len(subset)} feature\"\n",
    "\n",
    "        # Her segment İçin 1D feature, 2D görsel ve label Ekle.\n",
    "        for i, img_name in enumerate(tqdm(img_files, desc=f\"{split}/{label}\")):\n",
    "            # 1D feature\n",
    "            features = subset.iloc[i, 5:].values.astype(np.float32)   # ilk 5 sütun meta, sonrası feature\n",
    "            X1.append(features)\n",
    "            # 2D image\n",
    "            img_path = os.path.join(img_dir, img_name)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_arr = np.array(img).astype(np.float32) / 255.0\n",
    "            X2.append(img_arr)\n",
    "            # Label\n",
    "            y.append(labels.index(label))  # label'ı int'e çevir\n",
    "\n",
    "    # Dataları numpy olarak kaydet (veya modeline doğrudan ver)\n",
    "    X1 = np.stack(X1)\n",
    "    X2 = np.stack(X2)\n",
    "    y = np.array(y)\n",
    "\n",
    "    np.save(f\"X1_{split}.npy\", X1)\n",
    "    np.save(f\"X2_{split}.npy\", X2)\n",
    "    np.save(f\"y_{split}.npy\", y)\n",
    "    print(f\"{split} split için shape: X1={X1.shape}, X2={X2.shape}, y={y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a507b34-cc0c-49aa-86ee-14852e747a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 1D feature extraction tamamlandı.\n",
      "Çıktı: C:\\Users\\VICTUS\\OneDrive\\Masaüstü\\EECSL\\all_segments_1d_features_new.csv\n",
      "Toplam segment: 1888\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import glob\n",
    "\n",
    "# ========== Parametreler ==========\n",
    "fs = 10240\n",
    "start_idx = int(1.5 * fs)\n",
    "end_idx   = int(4.5 * fs)\n",
    "segment_length = 1024\n",
    "\n",
    "# Yol ayarları (gerekirse değiştir)\n",
    "root_dir = r\"C:\\Users\\VICTUS\\OneDrive\\Masaüstü\\EECSL\"   # .mat klasörlerinin ana dizini\n",
    "index_map_path = os.path.join(root_dir, \"reassigned_index_map.csv\")  # 2D generator çıktısı\n",
    "save_csv_path  = os.path.join(root_dir, \"all_segments_1d_features_new.csv\")\n",
    "\n",
    "# ========== Yardımcılar ==========\n",
    "EPS = 1e-12\n",
    "\n",
    "def safe_std(x):\n",
    "    s = np.std(x)\n",
    "    return s if s > EPS else EPS\n",
    "\n",
    "def safe_mean_abs(x):\n",
    "    m = np.mean(np.abs(x))\n",
    "    return m if m > EPS else EPS\n",
    "\n",
    "def safe_smr(x):\n",
    "    # square mean root = (mean(sqrt(|x|)))**2\n",
    "    smr = (np.mean(np.sqrt(np.abs(x))))**2\n",
    "    return smr if smr > EPS else EPS\n",
    "\n",
    "def extract_features(x):\n",
    "    \"\"\"\n",
    "    19 özellik — NaN/Inf korumalı.\n",
    "    x: 1D numpy array (float)\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=np.float64)\n",
    "    N = len(x)\n",
    "    mu = np.mean(x)\n",
    "    sd = safe_std(x)\n",
    "    abs_mean = safe_mean_abs(x)\n",
    "    smr = safe_smr(x)\n",
    "    rms = np.sqrt(np.mean(x**2) + EPS)\n",
    "    maxabs = np.max(np.abs(x))\n",
    "    z = (x - mu) / sd\n",
    "\n",
    "    f = {}\n",
    "    f['peak']               = maxabs\n",
    "    f['rms']                = rms\n",
    "    f['kurtosis']           = np.mean(z**4)\n",
    "    f['crest_factor']       = maxabs / rms\n",
    "    f['clearance_factor']   = (maxabs / np.mean(np.sqrt(np.abs(x)) + EPS))**2\n",
    "    f['impulse_factor']     = maxabs / abs_mean\n",
    "    f['shape_factor']       = rms / abs_mean\n",
    "    f['skewness']           = np.mean(z**3)\n",
    "    f['square_mean_root']   = smr\n",
    "    f['moment_5']           = np.mean(z**5)\n",
    "    f['moment_6']           = np.mean(z**6)\n",
    "    f['mean']               = mu\n",
    "    f['shape_factor2']      = smr / abs_mean\n",
    "    f['peak_to_peak']       = np.max(x) - np.min(x)\n",
    "    f['kurtosis_factor']    = f['kurtosis'] / ((np.mean(x**2) + EPS)**2)\n",
    "    f['std']                = sd\n",
    "    f['smoothness']         = 1 - np.sqrt(1 + sd**2)\n",
    "    f['uniformity']         = 1 - sd / (mu if abs(mu) > EPS else (np.sign(mu)*EPS or EPS))\n",
    "    # normal_neg_loglike: normal PDF ortalaması (adın orijinaline sadık kalındı)\n",
    "    f['normal_neg_loglike'] = (1.0 / (sd*np.sqrt(2*np.pi))) * np.exp(-((x-mu)**2) / (2*sd**2))\n",
    "    f['normal_neg_loglike'] = float(np.mean(f['normal_neg_loglike']))\n",
    "    return [f[k] for k in f]\n",
    "\n",
    "def resolve_mat_path(label, basename_safe):\n",
    "    \"\"\"\n",
    "    2D index_map'ten gelen 'basename' (muhtemelen boşluklar '_' yapılmış) ile .mat yolunu bulur.\n",
    "    Deneme sırası:\n",
    "      1) exact: {label}_start/{basename_safe}.mat\n",
    "      2) boşluk <-> '_' dönüşümü\n",
    "      3) wildcard (kısmi eşleşme) — başında/sonunda ek karakter varsa da bulmaya çalış.\n",
    "    Hiçbiri yoksa None döner.\n",
    "    \"\"\"\n",
    "    base_dir = os.path.join(root_dir, f\"{label}_start\")\n",
    "\n",
    "    # 1) exact\n",
    "    cand = os.path.join(base_dir, basename_safe + \".mat\")\n",
    "    if os.path.exists(cand):\n",
    "        return cand\n",
    "\n",
    "    # 2) '_' <-> ' ' dönüşümü\n",
    "    flipped = basename_safe.replace(\"_\", \" \")\n",
    "    cand2 = os.path.join(base_dir, flipped + \".mat\")\n",
    "    if os.path.exists(cand2):\n",
    "        return cand2\n",
    "\n",
    "    # 3) wildcard — her iki varyasyon için dene\n",
    "    # örn: SOME_NAME -> *SOME*NAME*.mat ve *SOME NAME*.mat\n",
    "    patt1 = os.path.join(base_dir, f\"*{basename_safe}*.mat\")\n",
    "    patt2 = os.path.join(base_dir, f\"*{flipped}*.mat\")\n",
    "\n",
    "    hits = glob.glob(patt1)\n",
    "    if not hits:\n",
    "        hits = glob.glob(patt2)\n",
    "\n",
    "    if hits:\n",
    "        # Eğer birden fazla eşleşme varsa en kısa isimliyi seç (daha muhtemel doğru)\n",
    "        hits.sort(key=lambda p: len(os.path.basename(p)))\n",
    "        return hits[0]\n",
    "\n",
    "    return None\n",
    "\n",
    "# ========== Ana akış ==========\n",
    "# 2D tarafın index map'ini oku\n",
    "idx_df = pd.read_csv(index_map_path)\n",
    "\n",
    "required_cols = {'split','label','filename','basename','signal_key','seg_start'}\n",
    "missing = required_cols - set(idx_df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Index map içinde beklenen kolonlar yok: {missing}\")\n",
    "\n",
    "# Çıktılar\n",
    "features_list = []\n",
    "meta_list     = []\n",
    "\n",
    "# .mat okuma cache (dosya × kanal)\n",
    "mat_cache = {}\n",
    "\n",
    "# Satır satır gez: her satır 2D görüntünün birebir tanımıdır\n",
    "for i, row in idx_df.iterrows():\n",
    "    split      = str(row['split'])\n",
    "    label      = str(row['label'])\n",
    "    filename   = str(row['filename'])       # 2D görsel dosya adı (eşleştirme için saklayacağız)\n",
    "    basename   = str(row['basename'])       # 2D yazarken \"safe\" olabilir (alt çizgi)\n",
    "    channel    = str(row['signal_key'])     # 'cur1' veya 'cur2'\n",
    "    seg_start  = int(row['seg_start'])      # 1.5–4.5s aralığındaki segment başlangıcı (örnek cinsinden)\n",
    "\n",
    "    # İlgili .mat dosyasının yolunu çöz\n",
    "    mat_path = resolve_mat_path(label, basename)\n",
    "    if mat_path is None:\n",
    "        print(f\"[UYARI] .mat bulunamadı -> label={label}, basename={basename}\")\n",
    "        continue\n",
    "\n",
    "    # Cache anahtarı ve okuma\n",
    "    cache_key = f\"{mat_path}__{channel}\"\n",
    "    if cache_key in mat_cache:\n",
    "        signal = mat_cache[cache_key]\n",
    "    else:\n",
    "        try:\n",
    "            matdata = scipy.io.loadmat(mat_path)\n",
    "        except Exception as e:\n",
    "            print(f\"[UYARI] .mat okunamadı: {mat_path} ({e})\")\n",
    "            continue\n",
    "\n",
    "        if channel not in matdata:\n",
    "            print(f\"[UYARI] Kanal yok: {channel} in {mat_path}\")\n",
    "            continue\n",
    "\n",
    "        signal_full = np.asarray(matdata[channel]).squeeze().astype(np.float64)\n",
    "        # 2D taraftaki ile aynı ön-işleme: normalize + 1.5–4.5s kırpma\n",
    "        signal_full = (signal_full - np.mean(signal_full)) / (np.std(signal_full) + EPS)\n",
    "        signal = signal_full[start_idx:end_idx]\n",
    "        mat_cache[cache_key] = signal\n",
    "\n",
    "    # segment sınır kontrolü\n",
    "    if seg_start + segment_length > len(signal):\n",
    "        print(f\"[UYARI] Segment sınırı aşıldı: {os.path.basename(mat_path)}, {channel}, start={seg_start}\")\n",
    "        continue\n",
    "\n",
    "    segment = signal[seg_start:seg_start+segment_length]\n",
    "\n",
    "    # Özellik çıkar\n",
    "    feat_vec = extract_features(segment)\n",
    "    features_list.append(feat_vec)\n",
    "\n",
    "    # Meta: split,label,filename (2D ile birebir eşleşme!), matfile stem, channel, start_index\n",
    "    mat_stem = os.path.splitext(os.path.basename(mat_path))[0]\n",
    "    meta_list.append([split, label, filename, mat_stem, channel, seg_start])\n",
    "\n",
    "# NumPy/DF ve kaydet\n",
    "if not features_list:\n",
    "    raise RuntimeError(\"Hiç özellik çıkarılamadı. Lütfen index_map ve .mat yollarını kontrol et.\")\n",
    "\n",
    "features_arr = np.array(features_list, dtype=np.float64)\n",
    "features_df  = pd.DataFrame(features_arr, columns=[f\"feat_{i+1}\" for i in range(features_arr.shape[1])])\n",
    "\n",
    "meta_df = pd.DataFrame(meta_list, columns=['split','label','filename','matfile','channel','start_index'])\n",
    "\n",
    "# Çıktı CSV: (split, label, filename, matfile, channel, start_index, feat_1..feat_19)\n",
    "out_df = pd.concat([meta_df, features_df], axis=1)\n",
    "out_df.to_csv(save_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"[OK] 1D feature extraction tamamlandı.\")\n",
    "print(f\"Çıktı: {save_csv_path}\")\n",
    "print(f\"Toplam segment: {len(out_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f29185-5e74-4d52-9a02-fa0458e09c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "my_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
